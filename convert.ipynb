{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24fbeac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def clean_json(json_path, is_group3=False):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    query_data = data[\"query\"]\n",
    "    corpus_data = data[\"corpus\"]\n",
    "    qrels_data = data[\"qrel\"]\n",
    "    processed_dataset = []\n",
    "\n",
    "    for query_id, doc_relevance_map in qrels_data.items():\n",
    "        if query_id not in query_data:\n",
    "            print(f\"Warning: Query ID {query_id} from qrels not found in query_data. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        query_text = query_data[query_id]\n",
    "\n",
    "        for code_id, relevance_score in doc_relevance_map.items():\n",
    "            if code_id not in corpus_data:\n",
    "                print(f\"Warning: Code ID {code_id} for Query ID {query_id} from qrels not found in corpus_data. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            code_text = corpus_data[code_id]\n",
    "\n",
    "            if not is_group3 and relevance_score == 0:\n",
    "                continue\n",
    "\n",
    "            processed_dataset.append({\n",
    "                \"query_id\": query_id,\n",
    "                \"query_text\": query_text,\n",
    "                \"code_id\": code_id,\n",
    "                \"code_text\": code_text,\n",
    "                \"relevance\": relevance_score\n",
    "            })\n",
    "    # extract the file name from the path\n",
    "    file_name = json_path.split('/')[-1].split('.')[0]\n",
    "    # create the output file name in cleaned/\n",
    "    output_file_name = f\"cleaned/{file_name}_cleaned.json\"\n",
    "    # write the processed dataset to a new JSON file\n",
    "    with open(output_file_name, 'w') as f:\n",
    "        json.dump(processed_dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "266780d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the json files under original/\n",
    "import os\n",
    "json_files = [f for f in os.listdir('original/') if f.endswith('.json')]\n",
    "# create cleaned/ directory if it doesn't exist\n",
    "if not os.path.exists('cleaned/'):\n",
    "    os.makedirs('cleaned/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18b690cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,\n",
       " ['reconstructed_group1_hash_renamed.json',\n",
       "  'reconstructed_group3_helper_as_part_of_groundtruth_original.json',\n",
       "  'reconstructed_group3_helper_as_part_of_groundtruth_usual_renamed.json',\n",
       "  'reconstructed_group3_helper_as_other_candidates_original.json',\n",
       "  'reconstructed_group1_asm_short.json',\n",
       "  'reconstructed_group3_asm_short.json',\n",
       "  'reconstructed_group2_hash_renamed.json',\n",
       "  'reconstructed_group3_asm_long.json',\n",
       "  'reconstructed_group2_wasm.json',\n",
       "  'reconstructed_group2_asm_short.json',\n",
       "  'reconstructed_group2_asm_long.json',\n",
       "  'reconstructed_group2_usual_renamed.json',\n",
       "  'reconstructed_group3_helper_as_part_of_groundtruth_hash_renamed.json',\n",
       "  'reconstructed_group1_asm_long.json',\n",
       "  'reconstructed_group1_usual_renamed.json',\n",
       "  'reconstructed_group1_wasm.json',\n",
       "  'reconstructed_group3_helper_as_part_of_groundtruth_wasm.json',\n",
       "  'reconstructed_group3_helper_as_other_candidates_hash_renamed.json',\n",
       "  'reconstructed_group2_original.json',\n",
       "  'reconstructed_group3_helper_as_other_candidates_usual_renamed.json',\n",
       "  'reconstructed_group1_original.json'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_files), json_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a250a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for json_file in json_files:\n",
    "    # check if the file is group3\n",
    "    if 'group3' in json_file:\n",
    "        clean_json(f'original/{json_file}', is_group3=True)\n",
    "    else:\n",
    "        clean_json(f'original/{json_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb3947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3403d67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
